{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_DBT_Binary_Classifier",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONw1P0DCAOpCn3muOlRkAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/einsteinxx/UCLA_BE223C_SPRING_2021/blob/main/VGG_DBT_Binary_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIwP1Z8W-vZU"
      },
      "source": [
        "# VGG_DBT\n",
        "This code will recreate the VGG16 layer model for use in classification of DBT images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iix74kj_aDNY",
        "outputId": "1add74eb-b0c4-4cfa-960e-bb0fe85fda78"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import gc  #debug memory leaks in matplotlib\n",
        "import csv #read in description files\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "#\n",
        "# Read Data from google drive\n",
        "#\n",
        "\n",
        "from google.colab import drive #for loading gdrive data\n",
        "from google.colab import files\n",
        "\n",
        "# install dependencies not included by Colab\n",
        "# use pip3 to ensure compatibility w/ Google Deep Learning Images \n",
        "!pip3 install -q pydicom \n",
        "!pip3 install -q tqdm \n",
        "!pip3 install -q imgaug\n",
        "!pip3 install -q pickle5\n",
        "\n",
        "import pydicom #to read dicom files\n",
        "from pydicom import dcmread\n",
        "import pickle5 as pickle; #generic storage of image arra\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "#show model design parameters with torchsummary\n",
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "from torch import FloatTensor\n",
        "from torch import tensor\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "### Enable GPU, if present\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if (train_on_gpu):\n",
        "    !nvidia-smi -L\n",
        "    !nvidia-smi \n",
        "    dev=torch.device(\"cuda\")\n",
        "else:\n",
        "    print('GPU NOT FOUND!!! USING CPU INSTEAD!!!!!')\n",
        "\n",
        "################################################################################\n",
        "# Try TPU setup --- version mismatches --- DISABLED \n",
        "#\n",
        "train_on_tpu =0 #enable TPUs\n",
        "if ((train_on_gpu == 0 ) and train_on_tpu == 1):\n",
        "    !pip3 install -q cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8.1-cp37-cp37m-linux_x86_64.whl\n",
        "    # imports the torch_xla package\n",
        "    import torch_xla\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    dev = xm.xla_device()\n",
        "    print('!!!! USING TPU!!!!')\n",
        "################################################################################\n",
        "#\n",
        "# Load data from google drive\n",
        "#\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "data_dir = '/content/gdrive/My Drive/DBT_DATA/IMG_ARRAYS'\n",
        "patch_dir = '/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES' \n",
        "model_dir = '/content/gdrive/My Drive/BE223C_SPRING_2021/MODEL_SAVE'\n",
        "tensorboard_dir = '/content/gdrive/My Drive/BE223C_SPRING_2021/TENSORBOARD_SUMMARIES'\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-6fcc819f-4c89-9051-c001-7d59cd54da37)\n",
            "Tue Jun 15 20:27:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    24W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qbdm9drnHRBh"
      },
      "source": [
        "#GET LIST OF PRE-GENERATED CATEGORIES AVAILABLE\n",
        "These files were pre-built patches generated from the TRAINING DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G49j_VOIdgA6"
      },
      "source": [
        "################################################################################\n",
        "# GET FULL LIST OF FILES IN IMAGE ARRAY DIRECTORY\n",
        "################################################################################\n",
        "use_patch_files = 1\n",
        "if (use_patch_files == 0):\n",
        "    raw_files = os.listdir(data_dir)\n",
        "    print('found #files: ',len(raw_files))\n",
        "else: #patches broken up into directories\n",
        "    category_folders = os.listdir(patch_dir)\n",
        "    #raw_files = os.listdir(data_dir)\n",
        "    #print('found #files: ',len(raw_files))    \n",
        "\n",
        "if (0):\n",
        "    #create fake patches for now\n",
        "    patch_dict = {}\n",
        "    for counter,filename in enumerate(raw_files):\n",
        "        #load full array\n",
        "        full_filename = os.path.join(data_dir,filename)\n",
        "        img_data = pickle.load( open( full_filename, \"rb\" ) )\n",
        "        patch_data = img_data[0:3,:,:]\n",
        "        patch_dict[counter]= patch_data\n",
        "        print(full_filename,np.shape(patch_data))\n",
        "\n",
        "        if (counter > 0):\n",
        "            break\n",
        "        \n",
        "### SKIP ACTIONABLE FOLDER\n",
        "### Remove actionable folder item from list, since we're no longer using that data\n",
        "category_folders.remove('ACTIONABLE')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHIoRaYIIi2v"
      },
      "source": [
        "#GENERATE LIST OF PATCH FILES IN CATEGORY FOLDERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSX1m2-J6Wtv",
        "outputId": "27a3601c-c8df-4660-d52c-f41e9aed9efc"
      },
      "source": [
        "category_folders = ['NORMAL','CANCER']\n",
        "for ii in category_folders:\n",
        "    print(ii)\n",
        "    flist = os.listdir(os.path.join(patch_dir,ii))\n",
        "\n",
        "temp = flist[0].split(sep='_')\n",
        "print(temp[3])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NORMAL\n",
            "CANCER\n",
            "Cancer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1imG1PoIyOr"
      },
      "source": [
        "#BUILD INDIVIDUAL FILES LIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "Lt9XjPYGlvEm",
        "outputId": "918a072e-d825-42a7-83f7-b7b02d56f19f"
      },
      "source": [
        "#generate full file list for use in indexing the dataloader\n",
        "#this replaces the older loader, which was only inputting Normal\n",
        "full_file_list = [] #store the full filename of every file\n",
        "full_category_name = []\n",
        "for category_folder in category_folders:\n",
        "            print('------------- ',category_folder)\n",
        "            file_list = os.listdir(os.path.join(patch_dir,category_folder))\n",
        "            cat_count = 0\n",
        "            for file_name in file_list:\n",
        "                cat_count = cat_count + 1\n",
        "                full_category_name.append(category_folder)\n",
        "                full_file_list.append(file_name)\n",
        "                #print(os.path.join(category_folder,file_name))\n",
        "            print('------->category & count ',category_folder, cat_count)\n",
        "full_file_count = len(full_file_list)\n",
        "print(len(full_file_list))\n",
        "full_file_list[0]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------  NORMAL\n",
            "------->category & count  NORMAL 1714\n",
            "-------------  CANCER\n",
            "------->category & count  CANCER 1890\n",
            "3604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'DBT-P00949_DBT-S01343_lcc_Normal_s40_cx515_cy1379_244_244_FLIPH.pickle'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v5cqjurJk50"
      },
      "source": [
        "#CLASS FOR OUR CUSTOM DATA FORMAT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp7kwrfSlK2r"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms  #get normalization functions\n",
        "\n",
        "class CustomImageDataset(): #Dataset):\n",
        "    def __init__(self, img_dir,category=[],file_count=1,file_list =[],transform=None, target_transform=None):\n",
        "        #self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.category = category\n",
        "        self.file_count = file_count\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.category_name =''\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def image_normalize(image):\n",
        "        #replace with the more tensor friendly normalize once tensor shapes confirmed\n",
        "        image = image/65535.0\n",
        "        return image\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.file_count #len(self.file_list) #99 #len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        fname = self.file_list[index]\n",
        "\n",
        "        #get label and pull category \n",
        "        text_tokens = fname.split(sep='_')\n",
        "        label_class = text_tokens[3] #get the label token in 4th position\n",
        "        self.category_name =  label_class.upper() \n",
        "\n",
        "\n",
        "        full_file_name = os.path.join(self.img_dir,self.category_name,fname)\n",
        "        image = pickle.load( open( full_file_name, \"rb\" ) )\n",
        "        image = image.astype(float) #using patch images\n",
        "        \n",
        "\n",
        "        #VERIFY THE IMAGES ARE ALL THE SAME 3x244x244\n",
        "        shapes = image.shape\n",
        "        assert (shapes[0] == 3),\"Image slice error: {0}\".format(fname)\n",
        "        assert (shapes[1] == 244), print('Image row error: ',fname)\n",
        "        assert (shapes[2] == 244), print('Image column error: ',fname)\n",
        "        #if (shapes[0] != 3 and shapes[1] != 244 and shapes[2]!= 244):\n",
        "\n",
        "\n",
        "        #Normalize the data to 0,1 from 2^16\n",
        "        image = image/65535.0 #image_normalize(image)\n",
        "\n",
        "\n",
        "\n",
        "        #test out numeric label\n",
        "        if (label_class in 'Normal'):\n",
        "            label = 0\n",
        "        elif (label_class in 'Actionable'):\n",
        "            print('!!!!! ACTIONABLE PASSED THROUGH')\n",
        "            stop()\n",
        "            label = 1\n",
        "        elif (label_class in 'Benign'):\n",
        "            label = 0\n",
        "        else: # (label_class in 'Cancer'):\n",
        "            label = 1\n",
        "\n",
        "\n",
        "        #print(full_file_name)\n",
        "\n",
        "\n",
        "        #read_image(img_path)\n",
        "        #label = self.img_labels.iloc[idx, 1]\n",
        "        #if self.transform:\n",
        "        #    image = self.transform(image)\n",
        "        #if self.target_transform:\n",
        "        #    label = self.target_transform(label)\n",
        "        sample = {\"image\": image, \"label\": label}\n",
        "            #sample = file_name\n",
        "        return sample\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMgHH9EkKJsK"
      },
      "source": [
        "#GENERATE WEIGHTING FOR UNEVEN CLASSES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vH5Cqast3JR",
        "outputId": "836a8c67-fa4a-4b10-9e9b-02387fb06a81"
      },
      "source": [
        "#\n",
        "# Adjust the weighting and sampling of the training data to correct for any\n",
        "#imbalances. This is used in loss and dataloading\n",
        "#\n",
        "\n",
        "#GENERATE THE WEIGHT TENSOR BASED UPON THE LABEL APPLIED\n",
        "weight_list =[]\n",
        "for ii in  full_file_list:\n",
        "        \n",
        "    for jj in ii:\n",
        "        if ('Normal' in jj):\n",
        "            wval = 1\n",
        "        elif ('Benign' in jj):\n",
        "            wval = 3\n",
        "        else:\n",
        "            wval = 5\n",
        "\n",
        "        weight_list.append(wval)\n",
        "\n",
        "    #count = count + len(nfiles)\n",
        "number_weight_values = len(weight_list)\n",
        "number_weight_values = torch.tensor(number_weight_values)\n",
        "print('Number of weight values = ',number_weight_values)\n",
        "\n",
        "#target_list = full_file_list[torch.randperm(len(full_file_list))]\n",
        "weight_numbers = torch.tensor([1.0,20.0], dtype=torch.float32)\n",
        "\n",
        "#class_weights = [num_samples/class_counts[i] for i in range(len(class_counts))]\n",
        "#weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
        "sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weight_list), int(4))\n",
        "\n",
        "\n",
        "#sampler = torch.utils.data.WeightedRandomSampler(weights=weight_numbers, \n",
        "#                                                 num_samples=number_weight_values, replacement=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of weight values =  tensor(3247075)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4bVXZuDKkuF"
      },
      "source": [
        "#SPLIT DATA INTO SETS AND SETUP DATALOADERS\n",
        "-- save off the indices for each dataset (for testing with isolated data later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1p45uP4oi6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e05038-e8af-4ab6-8598-ceeef00f0739"
      },
      "source": [
        "\n",
        "\n",
        "#\n",
        "count =0\n",
        "# Setup the custom dataset\n",
        "for ii in category_folders:\n",
        "        nfiles = os.listdir(os.path.join(patch_dir,ii))\n",
        "        count = count + len(nfiles)\n",
        "print('Number of patch files found = ',count)\n",
        "\n",
        "#load up with the pre-sized patch images\n",
        "training_data = CustomImageDataset(img_dir=patch_dir,\n",
        "                                   category = full_category_name, \n",
        "                                   file_count=full_file_count,\n",
        "                                   file_list = full_file_list, \n",
        "                                   transform=None, \n",
        "                                   target_transform=None)\n",
        "\n",
        "#\n",
        "# TEST OUT SPLITTING DATASETS INTO TRAIN/TEST\n",
        "#\n",
        "train_size = int(0.1 * len(training_data))\n",
        "val_size = int(0.1 * len(training_data))\n",
        "test_size = len(training_data) - train_size - val_size\n",
        "train_subset, val_subset, test_subset = torch.utils.data.random_split(training_data, [train_size, val_size,test_size])\n",
        "\n",
        "\n",
        "bsize = 50\n",
        "#training_data = CustomImageDataset( annotations_file='', img_dir=data_dir, file_list=raw_files,transform=None, target_transform=None)\n",
        "if (train_on_gpu==1):\n",
        "    print('setting GPU data loads')\n",
        "    dataloader_training = DataLoader(train_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "    dataloader_validation = DataLoader(val_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "    dataloader_test = DataLoader(test_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "elif ((train_on_tpu == 1) and (train_on_gpu == 0)):\n",
        "    print('setting TPU data loads')\n",
        "    dataloader_training = DataLoader(train_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "    dataloader_validation = DataLoader(val_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "    dataloader_test = DataLoader(test_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "\n",
        "else:\n",
        "    dataloader_training = DataLoader(train_subset, batch_size=bsize,shuffle=True, num_workers=2)#, sampler=sampler) #only 2 workers for Colab CPU\n",
        "    dataloader_validation = DataLoader(val_subset, batch_size=bsize,shuffle=True, num_workers=2,drop_last=True)#, sampler=sampler) #only 2 workers for Colab CPU\n",
        "    dataloader_test = DataLoader(test_subset, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n",
        "\n",
        "\n",
        "############################################\n",
        "if (0): #disable while testing above, but this works\n",
        "    bsize = 8\n",
        "    #training_data = CustomImageDataset( annotations_file='', img_dir=data_dir, file_list=raw_files,transform=None, target_transform=None)\n",
        "    if (train_on_gpu):\n",
        "        dataloader = DataLoader(training_data, batch_size=bsize,shuffle=True, num_workers=4) #only 2 workers for Colab CPU\n",
        "    else:\n",
        "        dataloader = DataLoader(training_data, batch_size=bsize,shuffle=True, num_workers=2) #only 2 workers for Colab CPU\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of patch files found =  46375\n",
            "setting GPU data loads\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFUxceS3LKFr"
      },
      "source": [
        "#WRITE DATA INDICES TO STORAGE FOR USE LATER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_5NLA9Ri29j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3055cdc4-0de8-4a64-b8eb-da94371b5625"
      },
      "source": [
        "#\n",
        "# Save file indices for later testing of the final model\n",
        "#--RUN THIS EVERY TIME YOU USE DATALOADER!!!!! This will give the indices to the\n",
        "#test files so you can test on them separately\n",
        "\n",
        "val_index = dataloader_validation.dataset.indices\n",
        "test_index = dataloader_test.dataset.indices\n",
        "len(dataloader_validation.dataset.dataset.file_list)\n",
        "index_file = os.path.join(tensorboard_dir,'data_index.pickle')\n",
        "pickle.dump([val_index, test_index, file_list],open( index_file, \"wb\" ),protocol=5 )\n",
        "print('Saved off Val and Test dataloader indices')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved off Val and Test dataloader indices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-x-rQSkAbxQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNyc0Qzc3naC"
      },
      "source": [
        "### DEBUG\n",
        "#for ii in training_data:\n",
        "#    print(ii)\n",
        "#print(full_file_list[401])\n",
        "#d = next(iter(dataloader_training))\n",
        "#print(len(d['image']), len(d['label']))\n",
        "#print(d['label'])\n",
        "if (0):\n",
        "    for i, _ in enumerate(dataloader_training, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        #inputs, labels = data\n",
        "        pass\n",
        "        #print(type(data['image']))\n",
        "\n",
        "\n",
        "        if (i > 0):\n",
        "            break\n",
        "\n",
        "if (0):\n",
        "    #Mixing GPU and CPU model saves doesn't seem to map well yet\n",
        "    final_file = os.path.join(model_dir,'vgg16_best_accuracy_97_gpu')\n",
        "    checkpoint = torch.load(final_file, map_location=torch.device('cpu'))\n",
        "    #model_vgg16 = VGG16(*args, **kwargs)\n",
        "    #model_vgg16.load_state_dict(torch.load(PATH))\n",
        "    \n",
        "    #model_vgg16.load_state_dict(checkpoint)\n",
        "    #best_acc = checkpoint['acc']\n",
        "    #start_epoch = checkpoint['epoch']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qLhCIFqNApu"
      },
      "source": [
        "#DEFINE MODEL LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea5d1nDDVt1t",
        "outputId": "2cd47965-205f-43f3-8109-4bc6dfadca8c"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.vgg16_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),  \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),         \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),        \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),            \n",
        "            nn.ReLU(inplace=True),         \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),         \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            #flattening layer before the linear??\n",
        "            nn.Flatten(), #testing this out before FC layers\n",
        "            nn.Linear(25088, 4096), #in should match 512x512 above\n",
        "            nn.ReLU(inplace=True), #testing this layer out instead of softmax\n",
        "            nn.Linear(4096,2))#, switched to binary class\n",
        "            #nn.Softmax(dim=1))\n",
        "        #nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        #self.linear_layers = Sequential(\n",
        "        #    Linear(4 * 7 * 7, )\n",
        "        #)\n",
        "\n",
        "#transform_test = transforms.Compose([\n",
        "#    transforms.ToTensor(),\n",
        "#    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "#])\n",
        "\n",
        "    def forward(self, x):\n",
        "        #self.flatten = nn.Flatten()\n",
        "        #x = self.flatten(x)\n",
        "        #print('fwd shape x = ',x.shape)\n",
        "        logits = self.vgg16_stack(x)\n",
        "        #print('logits out = ', logits.shape)\n",
        "        \n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "model_vgg16 = VGG16() #.to(device)\n",
        "model_vgg16 = model_vgg16.float()\n",
        "print(model_vgg16)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG16(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (vgg16_stack): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): ReLU(inplace=True)\n",
            "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (23): Flatten(start_dim=1, end_dim=-1)\n",
            "    (24): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCYkVCHmm3Ob"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3E4ly00NHgl"
      },
      "source": [
        "#*EXPERIMENTAL* TPU INFO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmD0A9SkmDrC"
      },
      "source": [
        "\n",
        "#\n",
        "# GET TPU Information  --- use only when GPU has timed out\n",
        "# EXPERIMENT!!!!\n",
        "if (train_on_tpu == 1):\n",
        "    import tensorflow as tf\n",
        "    bsize=50\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    # This is the TPU initialization code that has to be at the beginning.\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad4zimJYNQpX"
      },
      "source": [
        "#CLEAR GPU CACHE\n",
        "*   Clear the GPU cache during long debug sessions\n",
        "*   restarting the instance doesn't always seem to clear the GPU mem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URt7A8iTUka2",
        "outputId": "026a66e1-d439-4e8d-d697-85bf4d8583fa"
      },
      "source": [
        "#clear GPU cache if needed\n",
        "\n",
        "try_to_clear = 0\n",
        "if (try_to_clear == 1):\n",
        "    del model_vgg16\n",
        "    mem_alloc = torch.cuda.memory_allocated(dev)\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache() #   clear_cache\n",
        "\n",
        "    print('memory allocated is ', mem_alloc)\n",
        "else:\n",
        "    print('SKIP GPU MEM CLEAR---')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SKIP GPU MEM CLEAR---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBJ9QI3rN3AH"
      },
      "source": [
        "#SHOW MODEL SUMMARY WITH BATCH SIZING "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDWdC1VVgkXg",
        "outputId": "cbd8b3b7-b406-42e1-b798-d37e2e72a56e"
      },
      "source": [
        "#Show summary of model setup and move model to the GPU\n",
        " #train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if (train_on_gpu == 1):\n",
        "    #dev=torch.device(\"cuda\") \n",
        "    model_vgg16.to(dev)\n",
        "    summary(model_vgg16,(3,244,244), batch_size = bsize, device='cuda')\n",
        "elif ( (train_on_tpu == 1) and (train_on_gpu == 0)):\n",
        "    ### TPU with pytorch has some issues\n",
        "    model_vgg16.to(dev)\n",
        "    summary(model_vgg16,(3,244,244), batch_size = bsize, device=dev)\n",
        "else:\n",
        "    summary(model_vgg16,(3,244,244), batch_size = bsize)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [50, 64, 244, 244]           1,792\n",
            "            Conv2d-2         [50, 64, 244, 244]          36,928\n",
            "              ReLU-3         [50, 64, 244, 244]               0\n",
            "         MaxPool2d-4         [50, 64, 122, 122]               0\n",
            "            Conv2d-5        [50, 128, 122, 122]          73,856\n",
            "            Conv2d-6        [50, 128, 122, 122]         147,584\n",
            "              ReLU-7        [50, 128, 122, 122]               0\n",
            "         MaxPool2d-8          [50, 128, 61, 61]               0\n",
            "            Conv2d-9          [50, 256, 61, 61]         295,168\n",
            "           Conv2d-10          [50, 256, 61, 61]         590,080\n",
            "           Conv2d-11          [50, 256, 61, 61]         590,080\n",
            "             ReLU-12          [50, 256, 61, 61]               0\n",
            "        MaxPool2d-13          [50, 256, 30, 30]               0\n",
            "           Conv2d-14          [50, 512, 30, 30]       1,180,160\n",
            "           Conv2d-15          [50, 512, 30, 30]       2,359,808\n",
            "           Conv2d-16          [50, 512, 30, 30]       2,359,808\n",
            "             ReLU-17          [50, 512, 30, 30]               0\n",
            "        MaxPool2d-18          [50, 512, 15, 15]               0\n",
            "           Conv2d-19          [50, 512, 15, 15]       2,359,808\n",
            "           Conv2d-20          [50, 512, 15, 15]       2,359,808\n",
            "           Conv2d-21          [50, 512, 15, 15]       2,359,808\n",
            "             ReLU-22          [50, 512, 15, 15]               0\n",
            "        MaxPool2d-23            [50, 512, 7, 7]               0\n",
            "          Flatten-24                [50, 25088]               0\n",
            "           Linear-25                 [50, 4096]     102,764,544\n",
            "             ReLU-26                 [50, 4096]               0\n",
            "           Linear-27                    [50, 2]           8,194\n",
            "================================================================\n",
            "Total params: 117,487,426\n",
            "Trainable params: 117,487,426\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 34.07\n",
            "Forward/backward pass size (MB): 9572.41\n",
            "Params size (MB): 448.18\n",
            "Estimated Total Size (MB): 10054.66\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZOqBOy9OFBg"
      },
      "source": [
        "#DEFINE LOSS SESTUP AND OPTIMIZERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY_ek5CWuvLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d389425a-9d67-419e-90a2-f243643aa764"
      },
      "source": [
        "#\n",
        "# LOSS FUNCTION SETUP\n",
        "#\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "import torch\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = weight_numbers)\n",
        "if (train_on_gpu ==1):\n",
        "    criterion.cuda(dev)\n",
        "\n",
        "#OPTIMIZERS\n",
        "#optimizer = optim.SGD(model_vgg16.parameters(), lr=0.1, momentum = 0.99) #lr=0.001, momentum=0.9)\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "optimizer = torch.optim.Adam(model_vgg16.parameters(), lr=0.01, weight_decay=0.00000)#lr=0.00005, weight_decay=0.0000)\n",
        "\n",
        "#add scheduler to adjust learning rates when val gets stuck\n",
        "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.1)\n",
        "\n",
        "if (train_on_gpu == 1):\n",
        "    m = nn.LogSoftmax(dim=1).cuda(dev)\n",
        "    nll_loss = nn.NLLLoss().cuda(dev)\n",
        "else:\n",
        "    m = nn.LogSoftmax(dim=1)\n",
        "    nll_loss = nn.NLLLoss()\n",
        "\n",
        "L1loss = nn.L1Loss()\n",
        "\n",
        "model_vgg16.parameters\n",
        "#summary(model_vgg16, (3, 224, 224))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of VGG16(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (vgg16_stack): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU(inplace=True)\n",
              "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (23): Flatten(start_dim=1, end_dim=-1)\n",
              "    (24): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvu7z1XuILhw"
      },
      "source": [
        "#tensorboard for debugging views\n",
        "use_tensor_board = 1\n",
        "if (use_tensor_board == 1):\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    writer = SummaryWriter(tensorboard_dir)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7jbtrd8Gpd"
      },
      "source": [
        "#Look at Tensorboard info\n",
        "if (0):\n",
        "    !pip3 install -q tensorboard\n",
        "    %tensorboard --logdir=tensorboard_dir"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpu_EjXk-VqJ"
      },
      "source": [
        "def calculate_metrics(labels, y_pred_tags):\n",
        "    #calculate PRECISION and other metrics to guage the model results\n",
        "    #get # of true cancer cases, find # of cancer cases falsely predicted\n",
        "    from sklearn.metrics import average_precision_score\n",
        "\n",
        "    temp_labels = []\n",
        "    temp_prediction = []\n",
        "    true_pos =[]\n",
        "\n",
        "\n",
        "    #initialize variables for manual calculations\n",
        "    TP = 0 #true positive\n",
        "    FP = 0 #false positive\n",
        "    TN = 0 #true negative\n",
        "    FN = 0 #false negative\n",
        "    BP = 0 #benign positive match\n",
        "    BN = 0 #benign negative match\n",
        "    num0=0\n",
        "    num1=0\n",
        "    num2=0\n",
        "    for i in range(len(labels)): \n",
        "        if y_pred_tags[i]==labels[i]==1:\n",
        "            TP += 1\n",
        "\n",
        "        #FP\n",
        "        if y_pred_tags[i]==1 and labels[i]!=y_pred_tags[i]:\n",
        "            FP += 1\n",
        "        #if y_pred_tags[i]==1 and labels[i]!=y_pred_tags[i]:\n",
        "        #    FP += 1\n",
        "\n",
        "        #TN\n",
        "        if labels[i]==y_pred_tags[i]==0:\n",
        "            TN += 1\n",
        "        #if labels[i]==y_pred_tags[i]==1:\n",
        "        #    TN += 1\n",
        "\n",
        "        #FN\n",
        "        if y_pred_tags[i]==0 and labels[i]==1: #!=y_pred_tags[i]:\n",
        "            FN += 1\n",
        "        #if y_pred_tags[i]==1 and labels[i]==2: #!=y_pred_tags[i]:\n",
        "        #    FN += 1\n",
        "\n",
        "\n",
        "        if (y_pred_tags[i]==0):\n",
        "            num0+=1\n",
        "        elif (y_pred_tags[i] == 1):\n",
        "            num1+=1\n",
        "        else:\n",
        "            num2 +=1\n",
        "\n",
        "    #F1 Score = 2*(Recall * Precision) / (Recall + Precision)\n",
        "    print('Predicted Matches #0,#1,#2 = ',num0,num1,num2)\n",
        "\n",
        "    final_accuracy = (TP+TN)/(TP+FP+FN+TN +1e-12)\n",
        "    print('Accuracy is ',final_accuracy)\n",
        "    final_precision = TP/(TP+FP + 1e-12)\n",
        "    print('Precision is ',final_precision)\n",
        "    final_recall_sens = TP/(TP + FN + 1e-12)\n",
        "    print('Recall/Sens = ',final_recall_sens)\n",
        "    f1_score = 2 *(final_recall_sens * final_precision)/(final_recall_sens + final_precision +1e-12)\n",
        "    print('F1 score = ',f1_score)\n",
        "\n",
        "\n",
        "    #########################################################################\n",
        "    # Consolidate the 3 classes into a binary setup. Cancer label is 1, \n",
        "    #benign and no cancer are lumped into class 0\n",
        "    #########################################################################\n",
        "    for ii in labels:\n",
        "        if (ii == 1):\n",
        "            temp_labels.append(1)\n",
        "        else:\n",
        "            temp_labels.append(0)\n",
        "\n",
        "    for ii in y_pred_tags:\n",
        "        if (ii == 1):\n",
        "            temp_prediction.append(1)\n",
        "        else:\n",
        "            temp_prediction.append(0)\n",
        "    print(temp_labels)\n",
        "    print(temp_prediction) \n",
        "    print(labels)\n",
        "    print(y_pred_tags)                  \n",
        "    average_precision = average_precision_score(temp_labels, temp_prediction)\n",
        "\n",
        "    print('Average precision-recall score: {0:0.2f}'.format(\n",
        "        average_precision))\n",
        "    \n",
        "    scores = [TP, FP,TN,FN]\n",
        "    return average_precision, final_accuracy, final_precision, final_recall_sens, f1_score, scores"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bA94lc_wsYV"
      },
      "source": [
        "##########################################################\n",
        "# Test against the test dataset to get accuracy results\n",
        "##########################################################\n",
        "\n",
        "model_number = 99\n",
        "if (model_number == 1):\n",
        "    model_test = 'vgg16_best_accuracy_93_EPOCH_96_0.04582521319389343'\n",
        "    model_test_index = 'data_index_052521_gpu.pickle'\n",
        "elif (model_number == 2):\n",
        "    model_test = 'vgg16_best_accuracy_99_EPOCH_94_0.00040225533302873373'\n",
        "    model_test_index = 'data_index_052521_gpu.pickle'\n",
        "else:\n",
        "    model_test = 'vgg16_best_accuracy_99_EPOCH_140_0.005'\n",
        "    data_test_index = 'data_index_model3.pickle'\n",
        "run_test= 0\n",
        "if (run_test == 1):\n",
        "    #Mixing GPU and CPU model saves doesn't seem to map well yet\n",
        "    final_file = os.path.join(model_dir,model_test) #'vgg16_best_accuracy_81_EPOCH_79') #95_gpu_051821')#'vgg16_best_accuracy_97_gpu_final')\n",
        "    checkpoint = torch.load(final_file, map_location=torch.device('cpu'))\n",
        "    #model_vgg16 = VGG16(*args, **kwargs)\n",
        "    #model_vgg16.load_state_dict(torch.load(PATH))\n",
        "    index_file = os.path.join(tensorboard_dir,model_test_index) #052021_gpu.pickle') #data_index_last.pickle')\n",
        "    #[val_index, test_index, file_list]\n",
        "    #a,b,flist=pickle.load( open( index_file, \"rb\" )) \n",
        "    #model_vgg16.load_state_dict(checkpoint)\n",
        "    #best_acc = checkpoint['acc']\n",
        "    #start_epoch = checkpoint['epoch']\n",
        "    \n",
        "    use_index = 1\n",
        "    if (use_index == 1):\n",
        "        #[val_index, test_index, file_list]\n",
        "        validation_saved_index,test_saved_index,saved_flist=pickle.load( open( index_file, \"rb\" )) \n",
        "        test_files=[]\n",
        "        for ii in test_saved_index:\n",
        "            test_files.append(full_file_list[ii])\n",
        "        print('!!!! Using Test Indexed Files ONLY !!!!')\n",
        "    else: #use full files      \n",
        "        bc_files=[]\n",
        "        for ii in full_file_list:\n",
        "            if (('Benign' in ii) or ('Cancer' in ii)):\n",
        "                bc_files.append(ii)\n",
        "                #print(ii)\n",
        "    \n",
        "    #new_file_list=[]\n",
        "    #for ii in b:\n",
        "    #    new_file_list.append(full_file_list[ii])\n",
        "\n",
        "\n",
        "    model_vgg16.load_state_dict(checkpoint)\n",
        "    model_vgg16.eval()\n",
        "\n",
        "\n",
        "    #load up with the pre-sized patch images\n",
        "    all_data = CustomImageDataset(img_dir=patch_dir,\n",
        "                                    category = full_category_name, \n",
        "                                    file_count=len(test_files), #full_file_count,\n",
        "                                    file_list = test_files, #flist, #new_file_list, #full_file_list, \n",
        "                                    transform=None, \n",
        "                                    target_transform=None)\n",
        "\n",
        "    dataloader_all = DataLoader(all_data, batch_size=50,shuffle=True, num_workers=2)#, \n",
        "\n",
        "    total_accuracy = []\n",
        "    total_precision = []\n",
        "    total_average_precision=[] \n",
        "    total_final_accuracy = []\n",
        "    total_final_precision = []\n",
        "    total_final_recall_sens = []\n",
        "    total_f1_score =[]\n",
        "    total_TP = []\n",
        "    total_FP = []\n",
        "    total_TN = []\n",
        "    total_FN = []\n",
        "    for epoch in range(0,1):\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(dataloader_all, 0):\n",
        "                print(i)\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                #inputs, labels = data\n",
        "                inputs = data['image'].type(FloatTensor)\n",
        "                labels = data['label'] #.type(FloatTensor)\n",
        "\n",
        "                if (train_on_gpu):\n",
        "                    inputs, labels = inputs.to(dev), labels.to(dev)\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = model_vgg16(inputs) #.permute(0, 1, 2, 3))\n",
        "\n",
        "                outputs=torch.flatten(outputs, start_dim=1)\n",
        "                loss = criterion(outputs, labels.long())\n",
        "\n",
        "\n",
        "                #print(outputs)\n",
        "                y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
        "                _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "                #print(y_pred_tags)\n",
        "                #print(labels)\n",
        "                correct_pred = (y_pred_tags == labels).float()\n",
        "                accuracy = correct_pred.sum() / len(correct_pred)\n",
        "                #accuracy = torch.round(accuracy)\n",
        "\n",
        "\n",
        "                #Get advanced metrics\n",
        "                average_precision, final_accuracy, final_precision, final_recall_sens, f1_score, scores = calculate_metrics(labels,y_pred_tags)\n",
        "\n",
        "                total_average_precision.append(average_precision) \n",
        "                total_final_accuracy.append(final_accuracy)\n",
        "                total_final_precision.append(final_precision)\n",
        "                total_final_recall_sens.append(final_recall_sens)\n",
        "                total_f1_score.append(f1_score)\n",
        "                total_TP.append(scores[0])\n",
        "                total_FP.append(scores[1])\n",
        "                total_TN.append(scores[2])\n",
        "                total_FN.append(scores[3])\n",
        "\n",
        "                total_accuracy.append(accuracy)\n",
        "                \n",
        "                if (i%100 == 0):\n",
        "                    print('@ interim accuracy = ',i,  sum(total_accuracy)/len(total_accuracy))                \n",
        "                #print('-----#correct, training accuracy = ',correct_pred,accuracy)\n",
        "    print('Finished testing all data')\n",
        "    print('total accuracy = ', sum(total_accuracy)/len(total_accuracy))\n",
        "    test_p_file = os.path.join(tensorboard_dir,'test_metrics_052521.pickle')\n",
        "    pickle.dump([total_average_precision,total_final_accuracy, \n",
        "                 total_final_precision, total_final_recall_sens, \n",
        "                 total_f1_score, total_accuracy, \n",
        "                 total_TP, total_FP, total_TN, total_FN],\n",
        "                 open( test_p_file, \"wb\" ),protocol=5 )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhtlWWyUUQno"
      },
      "source": [
        "#\n",
        "# GENERATE TEST METRICS FOR DEBUGGING\n",
        "#\n",
        "\n",
        "if (run_test == 1):\n",
        "    test_p_file = os.path.join(tensorboard_dir,'test_metrics_052521.pickle')\n",
        "    tdata = pickle.load( open( test_p_file, \"rb\" ) )\n",
        "    print(len(tdata))\n",
        "    print(len(total_final_recall_sens))\n",
        "    total_accuracy = tdata[5]\n",
        "    print('Avg precision score (sklearn) = ',sum(total_average_precision)/len(total_average_precision))\n",
        "    print('Avg Final accuracy (TP+TN)/(TP+FP+FN+TN)  = ',sum(total_final_accuracy)/len(total_final_accuracy))\n",
        "    print('Avg Final precision TP/(TP+FP) = ',sum(total_final_precision)/len(total_final_precision))\n",
        "    print('Avg Final recall TP/(TP+FN) = ',sum(total_final_recall_sens)/len(total_final_recall_sens))\n",
        "    print('Avg F1 score 2(recall *precision)/(recall+precision)= ',sum(total_f1_score)/len(total_f1_score))\n",
        "    print('Avg Correct prediction&truth matching = ',sum(total_accuracy)/len(total_accuracy))\n",
        "    \n",
        "    fig, axs = plt.subplots(1,5,figsize = (20, 3))\n",
        "    fig.suptitle('Model results over Test Only Set', y=1.1)\n",
        "    axs[0].plot(total_average_precision)\n",
        "    axs[0].title.set_text('Avg Precision Score')\n",
        "    axs[0].set_xlabel('50 batch#')\n",
        "\n",
        "    axs[1].plot(total_final_accuracy)\n",
        "    axs[1].title.set_text('Avg Accuracy')\n",
        "    axs[1].set_xlabel('50 batch#')\n",
        "\n",
        "    axs[2].plot(total_final_precision)\n",
        "    axs[2].title.set_text('Avg Precision(manual)')\n",
        "    axs[2].set_xlabel('50 batch#')\n",
        "\n",
        "    axs[3].plot(total_final_recall_sens)\n",
        "    axs[3].title.set_text('Avg Final Recall Sensitivity')\n",
        "    axs[3].set_xlabel('50 batch#')\n",
        "\n",
        "    axs[4].plot(total_f1_score)\n",
        "    axs[4].title.set_text('Avg F1 Score')\n",
        "    axs[4].set_xlabel('50 batch#')\n",
        "\n",
        "\n",
        "    b_files=0\n",
        "    c_files = 0\n",
        "    n_files = 0\n",
        "    \n",
        "    for ii in test_files: #full_file_list[test_]:\n",
        "        if ('Benign' in ii):\n",
        "            b_files +=1\n",
        "        elif ('Cancer' in ii):\n",
        "            c_files += 1\n",
        "        else:\n",
        "            n_files +=1\n",
        "    print('Benign files, Cancer files,Normal files,Total files = ',b_files, c_files,n_files,b_files+c_files+n_files)\n",
        "#fig.suptitle('DBT-P01110 LCC CANCER slice34')\n",
        "\n",
        "\n",
        "    #\n",
        "    # Confusion Matrix\n",
        "    #\n",
        "\n",
        "    #scores = [TP, FP,TN,FN]\n",
        "    print(total_TP, total_FP,total_TN,total_FN)\n",
        "    #TP FN\n",
        "    #FP TN\n",
        "    print('       PREDICTED')\n",
        "    print('ACTUAL [' + str(sum(total_TP)) + '    ' + str(sum(total_FN)) + ']')\n",
        "    print('       [' + str(sum(total_FP)) + '    ' +str(sum(total_TN)) + ']')\n",
        "    #total_average_precision,total_final_accuracy, \n",
        "    #             total_final_precision, total_final_recall_sens, \n",
        "    #             total_f1_score, total_accuracy\n",
        "#        print('Predicted Matches #0,#1,#2 = ',num0,num1,num2)\n",
        "#    print('BN Match = ',BN,BP)\n",
        "#    final_accuracy = (TP+TN)/(TP+FP+FN+TN +1e-12)\n",
        "#    print('Accuracy is ',final_accuracy)\n",
        "#    final_precision = TP/(TP+FP + 1e-12)\n",
        "#    print('Precision is ',final_precision)\n",
        "#    final_recall_sens = TP/(TP + FN + 1e-12)\n",
        "#    print('Recall/Sens = ',final_recall_sens)\n",
        "#    f1_score = 2 *(final_recall_sens * final_precision)/(final_recall_sens + final_precision +1e-12)\n",
        "#    print('F1 score = ',f1_score)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp_zI8hfwFRL"
      },
      "source": [
        "### TRAIN THE NETWORK\n",
        "\n",
        "\n",
        "\n",
        "start_epoch = 0 #used for reloading model\n",
        "stop_epoch = 400\n",
        "training_loss = {}\n",
        "validation_loss = {}\n",
        "training_accuracy = {}\n",
        "validation_accuracy ={}\n",
        "tloss = []\n",
        "vloss = []\n",
        "\n",
        "best_accuracy = 0.0 #store highest accuracy for current model\n",
        "best_validation_loss = 0.0 #store highest validation loss over epochs\n",
        "best_validation_precision = 0.0 #store highest validation precision over epochs\n",
        "\n",
        "training_average_precision ={}\n",
        "training_final_accuracy ={}\n",
        "training_final_precision = {}\n",
        "training_final_recall_sens = {}\n",
        "training_f1_score = {}\n",
        "\n",
        "\n",
        "validation_average_precision = {}\n",
        "validation_final_accuracy = {}\n",
        "validation_final_precision = {}\n",
        "validation_final_recall_sens = {}\n",
        "validation_f1_score = {}\n",
        "\n",
        "##################################################################\n",
        "############# RESUME FROM EARLIER CHECKPOINT\n",
        "###################################################################\n",
        "resume_checkpoint = 0\n",
        "if (resume_checkpoint == 1):\n",
        "    #Mixing GPU and CPU model saves doesn't seem to map well yet\n",
        "    check_file = os.path.join(model_dir,'model_final_1')\n",
        "    checkpoint = torch.load(check_file, map_location=torch.device('cpu'))\n",
        "    model_vgg16.load_state_dict(checkpoint)\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    \n",
        "\n",
        "for epoch in range(start_epoch,stop_epoch): #(2):  # loop over the dataset multiple times\n",
        "\n",
        "    training_loss[epoch] = []\n",
        "    validation_loss[epoch] = []\n",
        "    training_accuracy[epoch] = []\n",
        "    validation_accuracy[epoch]= []\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "    #Advanced metrics based upon True/False values\n",
        "    training_average_precision[epoch] = []\n",
        "    training_final_accuracy[epoch] =[]\n",
        "    training_final_precision[epoch] = []\n",
        "    training_final_recall_sens[epoch] = []\n",
        "    training_f1_score[epoch] = []\n",
        "\n",
        "\n",
        "    validation_average_precision[epoch] = []\n",
        "    validation_final_accuracy[epoch] = []\n",
        "    validation_final_precision[epoch] = []\n",
        "    validation_final_recall_sens[epoch] = []\n",
        "    validation_f1_score[epoch]= []\n",
        "\n",
        "\n",
        "#\n",
        "# TRAINING SECTION\n",
        "#\n",
        "    model_vgg16.train()     # Optional when not using Model Specific layer\n",
        "    running_loss = 0.0\n",
        "    iteration_counter = 0 #keep track of total runs\n",
        "    #for i, data in enumerate(dataloader, 0):  #works for general setup!!\n",
        "    for i, data in enumerate(dataloader_training, 0):\n",
        "        model_vgg16.train() #reset if validation step kicked off\n",
        "        iteration_counter = iteration_counter + 1\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        #inputs, labels = data\n",
        "        inputs = data['image'].type(FloatTensor)\n",
        "        labels = data['label'] #.type(FloatTensor)\n",
        "\n",
        "        if (train_on_gpu):\n",
        "            inputs, labels = inputs.to(dev), labels.to(dev)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model_vgg16(inputs) #.permute(0, 1, 2, 3))\n",
        "        if (i == 0):\n",
        "            #show the initial sizes as a check\n",
        "            print(outputs.size())\n",
        "            print(labels.size())\n",
        "\n",
        "        ### L1 loss complains about outputs columns being out of order, permute\n",
        "        ### outputs to match up\n",
        "        use_L1 = 0\n",
        "        if (use_L1==1):\n",
        "            outputs= outputs.permute(3,1,2,0)\n",
        "            loss = L1loss(outputs,labels)\n",
        "        else:\n",
        "            #outputs = nn.Softmax2d(outputs)\n",
        "            \n",
        "            outputs=torch.flatten(outputs, start_dim=1)\n",
        "            #weight_balance = torch.tensor([0,0])\n",
        "            #loss = criterion(outputs, labels.long())\n",
        "            loss = criterion(outputs, labels.long())\n",
        "        training_loss[epoch].append(loss.item())\n",
        "        print('Loss = ', loss.item())\n",
        "\n",
        "        #\n",
        "        # ACCURACY\n",
        "        #\n",
        "        if (i%1 == 0):\n",
        "            #print(outputs)\n",
        "            y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
        "            _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "            print(y_pred_tags)\n",
        "            print(labels)\n",
        "            correct_pred = (y_pred_tags == labels).float()\n",
        "            accuracy = correct_pred.sum() / len(correct_pred)\n",
        "            #accuracy = torch.round(accuracy)\n",
        "            training_accuracy[epoch].append(accuracy)\n",
        "            print('-----#correct, training accuracy = ',correct_pred,accuracy)\n",
        "\n",
        "\n",
        "            #advanced metrics\n",
        "            average_precision_training, final_accuracy_training, \\\n",
        "            final_precision_training, final_recall_sens_training, \\\n",
        "            final_f1_score, scores = calculate_metrics(labels,y_pred_tags)\n",
        "\n",
        "            training_average_precision[epoch].append(average_precision_training)\n",
        "            training_final_accuracy[epoch].append(final_accuracy_training)\n",
        "            training_final_precision[epoch].append(final_precision_training)\n",
        "            training_final_recall_sens[epoch].append(final_recall_sens_training)\n",
        "            training_f1_score[epoch].append(final_f1_score)\n",
        "            print('TRAIN METRICS: ',average_precision_training, final_accuracy_training, final_precision_training, final_recall_sens_training, final_f1_score)\n",
        "        #\n",
        "        # TENSOR BOARD ADD\n",
        "        #\n",
        "        if (use_tensor_board == 1):\n",
        "            writer.add_scalar(\"Loss/train\", loss, epoch)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        if (i %500 == 0):\n",
        "            if(train_on_gpu == 1):\n",
        "                !nvidia-smi\n",
        "        if (i % 100 == 0):\n",
        "            running_loss += loss.item()\n",
        "            print('loop,epoch, loss, total running loss = ',i,epoch, loss.item(), running_loss/100)\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "###############################################\n",
        "# VALIDATION STEP\n",
        "###############################################\n",
        "    if (iteration_counter %1 == 0):\n",
        "        model_vgg16.eval()     # Optional when not using Model Specific layer\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for ii, vdata in enumerate(dataloader_validation, 0):\n",
        "                # get the inputs; data is a list of [inputs, labels]\n",
        "                #inputs, labels = data\n",
        "                vinputs = vdata['image'].type(FloatTensor)\n",
        "                vlabels = vdata['label'] #.type(FloatTensor)\n",
        "\n",
        "                #assert(len(vlabels) == bsize), \"Wrong number of val labels\"\n",
        "\n",
        "                if (train_on_gpu):\n",
        "                    vinputs, vlabels = vinputs.to(dev), vlabels.to(dev)\n",
        "\n",
        "                target = model_vgg16(vinputs)\n",
        "\n",
        "                #flatten for cross entropy loss\n",
        "                target=torch.flatten(target, start_dim=1)\n",
        "                loss = criterion(target,vlabels)\n",
        "                valid_loss = loss.item()# * data.size(0)\n",
        "                validation_loss[epoch].append(valid_loss)\n",
        "\n",
        "\n",
        "                y_val_softmax = torch.log_softmax(target, dim = 1)\n",
        "                _, y_val_tags = torch.max(y_val_softmax, dim = 1)\n",
        "                print('val prediction:',y_val_tags)\n",
        "                print('val truth lbls:',vlabels)\n",
        "                correct_pred = (y_val_tags == vlabels).float()\n",
        "                val_accuracy = correct_pred.sum() / len(correct_pred)\n",
        "                validation_accuracy[epoch].append(val_accuracy.item())\n",
        "                print('VALIDATION #correct, validation accuracy = ',correct_pred,val_accuracy)\n",
        "\n",
        "                #advanced metrics\n",
        "                average_precision_validation, final_accuracy_validation, final_precision_validation, final_recall_sens_validation, final_f1_score_validation, val_t_scores = calculate_metrics(vlabels,y_val_tags)\n",
        "\n",
        "                validation_average_precision[epoch].append(average_precision_validation)\n",
        "                validation_final_accuracy[epoch].append(final_accuracy_validation)\n",
        "                validation_final_precision[epoch].append(final_precision_validation)\n",
        "                validation_final_recall_sens[epoch].append(final_recall_sens_validation)\n",
        "                validation_f1_score[epoch].append(final_f1_score_validation)\n",
        "                print('VALIDATION METRICS: ',average_precision_validation, final_accuracy_validation, \n",
        "                      final_precision_validation, final_recall_sens_validation, final_f1_score_validation)\n",
        "\n",
        "                ################################################################\n",
        "                #SELECT MODEL TO SAVE \n",
        "                ################################################################\n",
        "                #if (  ((val_accuracy > best_accuracy) or (val_accuracy > 0.9)) and \n",
        "                if (  ((final_accuracy_validation > best_accuracy) or (final_accuracy_validation > 0.8)) and \n",
        "                    ((valid_loss <= 0.3) and (valid_loss >= 0.000001)) and \n",
        "                    ((average_precision_validation >= 0.70) or (average_precision_validation > best_validation_precision) )):\n",
        "                    print('!!!!!Accuracy < previous. Saving model. acc= ',val_accuracy)\n",
        "                    #store highest values, later iterations must beat these\n",
        "                    best_accuracy = final_accuracy_validation #val_accuracy\n",
        "                    best_validation_loss = valid_loss\n",
        "                    best_validation_precision = average_precision_validation\n",
        "                    #save this model off\n",
        "                    best_model_name = 'vgg16_best_accuracy_' + str(np.int(best_accuracy*100)) + '_EPOCH_' +str(epoch)+'_' + str(valid_loss)\n",
        "                    torch.save(model_vgg16.state_dict(),os.path.join(model_dir,best_model_name))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "# SAVE INTERMEDIATE FILES\n",
        "####################################################\n",
        "\n",
        "    training_pickle = os.path.join(tensorboard_dir,'tensor_training_loss.pickle')\n",
        "    validation_pickle = os.path.join(tensorboard_dir,'tensor_validation_loss.pickle')\n",
        "    accuracy_pickle = os.path.join(tensorboard_dir,'tensor_training_accuracy.pickle')\n",
        "    val_accuracy_pickle = os.path.join(tensorboard_dir,'tensor_validation_accuracy.pickle')\n",
        "    training_metrics_pickle = os.path.join(tensorboard_dir,'training_tp_metrics.pickle')\n",
        "    validation_metrics_pickle = os.path.join(tensorboard_dir,'validation_tp_metrics.pickle')\n",
        "\n",
        "\n",
        "    pickle.dump(training_loss, open( training_pickle, \"wb\" ),protocol=5 )\n",
        "    pickle.dump(validation_loss, open( validation_pickle, \"wb\" ),protocol=5 )\n",
        "    pickle.dump(training_accuracy,open( accuracy_pickle, \"wb\" ),protocol=5 )\n",
        "    pickle.dump(val_accuracy, open(val_accuracy_pickle,\"wb\"), protocol=5)\n",
        "\n",
        "\n",
        "\n",
        "    pickle.dump([training_average_precision, training_final_accuracy, training_final_precision, training_final_recall_sens, training_f1_score],  open(training_metrics_pickle, \"wb\"), protocol = 5)\n",
        "    pickle.dump([validation_average_precision, validation_final_accuracy, validation_final_precision, validation_final_recall_sens, validation_f1_score],  open(validation_metrics_pickle, \"wb\"), protocol = 5)\n",
        "\n",
        "    #save a midterm file\n",
        "    if (epoch %5 == 0):\n",
        "\n",
        "        save_model_mid = 'model_final_' + str(epoch) + '_' + str(np.int(best_accuracy*100))\n",
        "        torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model_vgg16.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': loss,\n",
        "                    }, os.path.join(model_dir,save_model_mid))\n",
        "\n",
        "    if (use_tensor_board == 1):\n",
        "        writer.flush() #write out all the info to the board\n",
        "\n",
        "torch.save(model_vgg16.state_dict(),os.path.join(model_dir,'vgg16_trained_final'))\n",
        "print('Finished Training')\n",
        "if (use_tensor_board == 1):\n",
        "    writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejJ354wGxkg0"
      },
      "source": [
        "'''\n",
        "#!ls '/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/CANCER/'\n",
        "#path that contains folder you want to copy\n",
        "%cd /content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORM_ORIGINAL\n",
        "print('changed dir')\n",
        "%cp   /content/gdrive/My\\ Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORM_ORIGINAL/* /content/gdrive/My\\ Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORMAL\n",
        "#%cp -av YOUR_FOLDER NEW_FOLDER_COPY\n",
        "#!cp -r '/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORM_ORIGINAL/*' '/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORMAL'\n",
        "'''\n",
        "import shutil\n",
        "import os\n",
        "count = 0\n",
        "if (1):\n",
        "    for f in os.listdir('/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORM_ORIGINAL'):\n",
        "        filename = os.path.join('/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORM_ORIGINAL',f)\n",
        "        if os.path.isfile(filename):\n",
        "            outfile = os.path.join('/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORM_ORIGINAL',f)\n",
        "            shutil.copy(outfile,'/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/NORMAL')\n",
        "            #print(f)\n",
        "            count +=1\n",
        "    print('found normal files, ',count)\n",
        "count = 0\n",
        "if (0):\n",
        "    for f in os.listdir('/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/BE_ORIGINAL'):\n",
        "        if os.path.isfile(f):\n",
        "            shutil.copy(f,'/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES/BENIGN')\n",
        "            count +=1\n",
        "    print('done copying benign. files, ', count)\n",
        "\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCXdhoQJfA11"
      },
      "source": [
        "#### Test out saved pickle files\n",
        "#tdata = training_pickle\n",
        "\n",
        "\n",
        "training_pickle = os.path.join(tensorboard_dir,'tensor_training_loss.pickle')\n",
        "validation_pickle = os.path.join(tensorboard_dir,'tensor_validation_loss.pickle')\n",
        "accuracy_pickle = os.path.join(tensorboard_dir,'tensor_training_accuracy.pickle')\n",
        "val_accuracy_pickle = os.path.join(tensorboard_dir,'tensor_validation_accuracy.pickle')\n",
        "training_metrics_pickle = os.path.join(tensorboard_dir,'training_tp_metrics.pickle')\n",
        "validation_metrics_pickle = os.path.join(tensorboard_dir,'validation_tp_metrics.pickle')\n",
        "\n",
        "\n",
        "\n",
        "tdata = pickle.load( open( training_pickle, \"rb\" ) )\n",
        "vdata =  pickle.load(open(validation_pickle,\"rb\"))\n",
        "#adata =  pickle.load(open(accuracy_pickle,\"rb\"))\n",
        "#val_acc = pickle.load(open( val_accuracy_pickle, \"rb\" ))\n",
        "training_metrics =  pickle.load(open(training_metrics_pickle,\"rb\"))\n",
        "val_metrics = pickle.load(open(validation_metrics_pickle,\"rb\"))\n",
        "#torch.load(accuracy_pickle,map_location=torch.device('cpu'))\n",
        "\n",
        "tdata.keys()\n",
        "\n",
        "total_losses= []\n",
        "epoint = []\n",
        "counter = 0\n",
        "for ii in tdata.keys():\n",
        "    for num in tdata[ii]:\n",
        "        total_losses.append(num)\n",
        "        counter+=1\n",
        "    epoint.append(counter)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(total_losses)\n",
        "plt.title('Training Loss')\n",
        "\n",
        "ax = plt.gca()\n",
        "#ax.set_xticks(epoint[0::10])\n",
        "#ax.xaxis.set_major_locator([1.1, 1.9, 2.5])\n",
        "\n",
        "total_validation = []\n",
        "for ii in vdata.keys():\n",
        "    for num in vdata[ii]:\n",
        "        total_validation.append(num)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(total_validation)\n",
        "plt.title('Validation Loss')\n",
        "\n",
        "\n",
        "#total_accuracy = []\n",
        "#for ii in adata.keys():\n",
        "#    for num in adata[ii]:\n",
        "#        total_accuracy.append(num)\n",
        "\n",
        "\n",
        "#plt.figure()\n",
        "#plt.plot(total_accuracy)\n",
        "#plt.title('Total Acc')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvPAsqqGUiu-"
      },
      "source": [
        "#\n",
        "#Disconnect from the VM to save our GPU time\n",
        "#\n",
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IG1u00h0biD"
      },
      "source": [
        "model_weights = [] # we will save the conv layer weights in this list\n",
        "conv_layers = [] # we will save the 49 conv layers in this list\n",
        "model_children = list(model_vgg16.children())\n",
        "print(len(model_children))\n",
        "print(model_children[1])\n",
        "\n",
        "\n",
        "# counter to keep count of the conv layers\n",
        "counter = 0 \n",
        "# append all the conv layers and their respective weights to the list\n",
        "for i in range(len(model_children[1])):\n",
        "    if type(model_children[1][i]) == nn.Conv2d:\n",
        "        counter += 1\n",
        "        model_weights.append(model_children[1][i].weight)\n",
        "        conv_layers.append(model_children[1][i])\n",
        "    elif type(model_children[1][i]) == nn.Sequential:\n",
        "        for j in range(len(model_children[1][i])):\n",
        "            for child in model_children[1][i][j].children():\n",
        "                if type(child) == nn.Conv2d:\n",
        "                    counter += 1\n",
        "                    model_weights.append(child.weight)\n",
        "                    conv_layers.append(child)\n",
        "print(f\"Total convolutional layers: {counter}\")\n",
        "print(len(model_weights))\n",
        "print(np.shape(model_weights[0]))\n",
        "\n",
        "# take a look at the conv layers and the respective weights\n",
        "for weight, conv in zip(model_weights, conv_layers):\n",
        "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
        "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# visualize the first conv layer filters\n",
        "print(np.shape(model_weights[3]))\n",
        "plt.figure(figsize=(20, 17))\n",
        "for i, filter in enumerate(model_weights[0]):\n",
        "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
        "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    #plt.savefig('../outputs/filter.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyxp-yp5xiCK"
      },
      "source": [
        "check_file = os.path.join(model_dir,'model_final_15')\n",
        "checkpoint = torch.load(check_file)#, map_location=torch.device('cpu'))\n",
        "#model_vgg16.load_state_dict(checkpoint)\n",
        "#best_acc = checkpoint['acc']\n",
        "#start_epoch = checkpoint['epoch']\n",
        "model_vgg16.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S09G-Y-0yTrm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-aNItv2-UbC"
      },
      "source": [
        "outputs #.softmax(dim=1)\n",
        "loss\n",
        "y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
        "_, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "print(y_pred_tags)\n",
        "print(labels)\n",
        "correct_pred = (y_pred_tags == labels).float()\n",
        "acc = correct_pred.sum() / len(correct_pred)\n",
        "\n",
        "acc = torch.round(acc * 100)\n",
        "print('correct_pred, accuracy = ',correct_pred,acc)\n",
        "#torch.flatten(outputs, start_dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXgCtKaWF9zY"
      },
      "source": [
        "#target.topk\n",
        "#target = model_vgg16(vinputs)\n",
        "target = outputs\n",
        "print(inputs.shape)\n",
        "#vout = model_vgg16(inputs)\n",
        "print(vout.shape)\n",
        "vout_save = vout\n",
        "\n",
        "#probabilities = torch.exp(vout).data\n",
        "\n",
        "# getting the topk (=5) probabilites and indexes\n",
        "# 0 -> probabilities\n",
        "# 1 -> index\n",
        "print('vout size = ', vout.shape)\n",
        "#probs = torch.log_softmax(target, dim=1)\n",
        "#probs = torch.softmax(vout.flatten, dim=1)\n",
        "probs = torch.flatten(vout,3)\n",
        "#print('prob shape = ',probs.shape)\n",
        "print(torch.softmax(probs,dim=0))\n",
        "#prob = torch.topk(probabilities, topk)[0].tolist()[0] # probabilities\n",
        "#index = torch.topk(probabilities, topk)[1].tolist()[0] # index\n",
        "print(probs[0,:].sum()/len(probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-hbpPftgQuX"
      },
      "source": [
        "import torch.nn.functional as nnf\n",
        "\n",
        "# ...\n",
        "prob = nnf.softmax(outputs, dim=1)\n",
        "\n",
        "top_p, top_class = prob.topk(1, dim = 1)\n",
        "print(top_p,top_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzwAPvmdqx_C"
      },
      "source": [
        "counter = 0\n",
        "for ii in dataloader_validation:\n",
        "    print(ii)\n",
        "    counter= counter + 1\n",
        "    if (counter > 0):\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWmfYzQVkJeA"
      },
      "source": [
        "#outputs=torch.flatten(outputs, start_dim=1)\n",
        "#loss = criterion(outputs, labels.long())\n",
        "\n",
        "outputs = model_vgg16(inputs) #.permute(0, 1, 2, 3))\n",
        "print(outputs.size())\n",
        "print(labels.size())\n",
        "a= torch.flatten(outputs,start_dim=1)\n",
        "\n",
        "print(outputs.mean())\n",
        "print(a)\n",
        "criterion(a,labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4BDZ5ZxXupV"
      },
      "source": [
        "#model_vgg16.state_dict()\n",
        "print(outputs.shape)\n",
        "a=outputs.view(4*512*7,4)\n",
        "print(a.shape)\n",
        "print(labels)\n",
        "x=torch.flatten(outputs, start_dim=1)\n",
        "\n",
        "#proper_target = torch.argmax(labels, dim=1)  # make sure keepdim=False\n",
        "#loss = criterion(outputs, proper_target)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvbWBBE_KooQ"
      },
      "source": [
        "torch.tensor([2])\n",
        "a=outputs/2\n",
        "a = torch.tensor(a)\n",
        "m = np.mean(inputs)\n",
        "b= inputs/1000\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVdV-EFSu9Gt"
      },
      "source": [
        "num_correct = 0\n",
        "total = 0\n",
        "model_vgg16.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(dataloader_test, 0):\n",
        "    #for data, labels in test_subset:\n",
        "        #data = data.to(device=device)\n",
        "        #labels = labels.to(device=device)\n",
        "        inputs = data['image'].type(FloatTensor)\n",
        "        labels = data['label'] #.type(FloatTensor)\n",
        "\n",
        "        predictions = model_vgg16(inputs) #for testing, only pass in images, no labels\n",
        "        predictions = predictions.permute(3,1,2,0)\n",
        "        num_correct += (predictions == labels).sum()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    print(f\"Test Accuracy of the model: {float(num_correct)/float(total)*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r88X8eSqIvV3"
      },
      "source": [
        "#\n",
        "# Test out every file for the correct shape\n",
        "#\n",
        "total_files = len(full_file_list)\n",
        "for counter, file_name in enumerate(full_file_list):\n",
        "\n",
        "    text_tokens = file_name.split(sep='_')\n",
        "    label_class = text_tokens[3] #get the label token in 4th position\n",
        "    category_name =  label_class.upper() \n",
        "\n",
        "    #print('testing file = ', counter, file_name)\n",
        "    cfile = os.path.join(patch_dir,category_name,file_name)\n",
        "    image = pickle.load( open( cfile, \"rb\" ) )\n",
        "    #print('testing ',cfile)\n",
        "    shape = np.shape(image)\n",
        "    if ((shape[0] != 3) or (shape[1] != 244) or (shape[2] != 244)):\n",
        "        print('Failed file ',file_name, shape)\n",
        "\n",
        "#    else:\n",
        "#        print('testing file = ', counter, file_name, shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqkjcMaMN6Nt"
      },
      "source": [
        "#patch_dir = '/content/gdrive/My Drive/DBT_WORKSPACE/TRAINING_PATCHES' \n",
        "!ls /content/gdrive/MyDrive/DBT_WORKSPACE/TRAINING_PATCHES/NORMAL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNv_YjYpWrRg"
      },
      "source": [
        "\n",
        "cfile = os.path.join(patch_dir,'NORMAL','DBT-P03406_DBT-S05192_lcc_Normal_s83_cx520_cy1165_244_244.pickle')\n",
        "image = pickle.load( open( cfile, \"rb\" ) )\n",
        "image.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}